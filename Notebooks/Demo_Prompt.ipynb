{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c1ced21",
   "metadata": {},
   "source": [
    "# Imports/Setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a429ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib3\n",
    "import requests\n",
    "import json\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "# Settings:\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f03f99",
   "metadata": {},
   "source": [
    "## Usage:\n",
    "\n",
    "OpenAI Model Information:\n",
    "* https://huggingface.co/openai/gpt-oss-20b\n",
    "* https://huggingface.co/openai/gpt-oss-120b\n",
    "\n",
    "\n",
    "Here's an example of how to query in python:\n",
    "\n",
    "```python\n",
    "data = {'model': 'gpt-oss:120b', 'prompt': 'Give me a haiku about low effort memes'}\n",
    "url = 'https://ollama.loweffort.meme/api/generate'\n",
    "\n",
    "with requests.post(url, json=data, stream=True, verify=False) as r:\n",
    "    for line in r.iter_lines():\n",
    "        if line:\n",
    "            j = json.loads(line)\n",
    "            if 'response' in j:\n",
    "                print(j['response'], end='')\n",
    "```\n",
    "\n",
    "And here is an example on curling via terminal:\n",
    "\n",
    "```\n",
    "curl -k https://ollama.loweffort.meme/api/generate \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  -d '{\n",
    "        \"model\": \"gpt-oss:120b\",\n",
    "        \"prompt\": \"Give me a haiku about low effort memes\"\n",
    "      }'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cfc92f",
   "metadata": {},
   "source": [
    "# Prompting Example (simple)\n",
    "\n",
    "This is just a simple 1-off query; there is no memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9132b56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ollama_response(data, url='https://ollama.loweffort.meme/api/generate'):\n",
    "    '''\n",
    "    Sends a streaming generation request to your local Ollama API.\n",
    "\n",
    "    Args:\n",
    "        data (dict): The JSON payload to send to Ollama, e.g.\n",
    "            {'model': 'gpt-oss:20b', 'prompt': 'Write a haiku about low effort memes'}\n",
    "\n",
    "    Returns:\n",
    "        str: The complete generated text response from the model.\n",
    "    '''\n",
    "\n",
    "    output = []\n",
    "\n",
    "    with requests.post(url, json=data, stream=True, verify=False) as r:\n",
    "        for line in r.iter_lines():\n",
    "            if line:\n",
    "                try:\n",
    "                    j = json.loads(line)\n",
    "                except Exception as e:\n",
    "                    print(f'DEBUG LINE: {line.decode()}')\n",
    "                    raise\n",
    "                if 'response' in j:\n",
    "\n",
    "                    # Stream output live:\n",
    "                    print(j['response'], end='')  \n",
    "                    output.append(j['response'])\n",
    "                    \n",
    "    # Newline after streaming:\n",
    "    print('\\n')\n",
    "    final_output = f'{''.join(output)}\\n'\n",
    "    return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e00d406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steam curls in the pot,  \n",
      "Fragrant broth warms the evening,  \n",
      "Comfort in a bowl.\n",
      "\n",
      "Sure thing! What was the subject of the first haiku? That way I can craft a second one that stays in the same theme.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Identify model and prompt:\n",
    "model = 'gpt-oss:20b'\n",
    "prompt = 'Give me a haiku about food'\n",
    "\n",
    "# Call function:\n",
    "data = {'model': model, 'prompt': prompt,}\n",
    "_ = generate_ollama_response(data)\n",
    "\n",
    "# Test for memory:\n",
    "prompt2 = 'Now give me a second haiku about the same thing as the first haiku, please.'\n",
    "data2 = {'model': model, 'prompt': prompt2,}\n",
    "_ = generate_ollama_response(data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc54eff",
   "metadata": {},
   "source": [
    "# Prompting Example (with Memory)\n",
    "\n",
    "To set up an agentic system, we'll need something like this to keep track of session memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77ef88bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OllamaChatSession:\n",
    "    '''\n",
    "    Manages a conversational session with an Ollama model using /api/chat.\n",
    "    Maintains memory (chat history) across turns and supports streaming output.\n",
    "    '''\n",
    "\n",
    "    def __init__(self,\n",
    "                 model: str = 'gpt-oss:20b',\n",
    "                 url: str = 'http://ollama.loweffort.meme/api/chat',\n",
    "                 system_prompt: Optional[str] = None,\n",
    "                 stream: bool = True):\n",
    "        self.model = model\n",
    "        self.url = url\n",
    "        self.stream = stream\n",
    "        self.messages: List[Dict[str, str]] = []\n",
    "        if system_prompt:\n",
    "            self.messages.append({'role': 'system', 'content': system_prompt})\n",
    "\n",
    "    def ask(self, prompt: str, verbose: bool = True) -> str:\n",
    "        '''Send a new user message and receive the assistant's response.'''\n",
    "        self.messages.append({'role': 'user', 'content': prompt})\n",
    "\n",
    "        data = {\n",
    "            'model': self.model,\n",
    "            'messages': self.messages,\n",
    "            'stream': self.stream\n",
    "        }\n",
    "\n",
    "        output = []\n",
    "        with requests.post(self.url, json=data, stream=self.stream) as r:\n",
    "            for line in r.iter_lines():\n",
    "                if not line:\n",
    "                    continue\n",
    "                j = json.loads(line)\n",
    "                msg = j.get('message', {}).get('content', '')\n",
    "                if msg:\n",
    "                    if verbose:\n",
    "                        print(msg, end='', flush=True)\n",
    "                    output.append(msg)\n",
    "        print()\n",
    "        full_response = ''.join(output)\n",
    "\n",
    "        # Store assistant reply in memory\n",
    "        self.messages.append({'role': 'assistant', 'content': full_response})\n",
    "        return full_response\n",
    "\n",
    "    def save_memory(self, path: str = 'ollama_memory.json'):\n",
    "        '''Persist chat memory to disk.'''\n",
    "        with open(path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(self.messages, f, indent=2)\n",
    "\n",
    "    def load_memory(self, path: str = 'ollama_memory.json'):\n",
    "        '''Load previous memory from disk.'''\n",
    "        try:\n",
    "            with open(path, 'r', encoding='utf-8') as f:\n",
    "                self.messages = json.load(f)\n",
    "        except FileNotFoundError:\n",
    "            print(f'No memory file found at {path}')\n",
    "\n",
    "    def clear_memory(self):\n",
    "        '''Reset chat memory except for any system message.'''\n",
    "        sys_msgs = [m for m in self.messages if m['role'] == 'system']\n",
    "        self.messages = sys_msgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e442fe48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Something super fun?**  \n",
      "\n",
      "-â€¯Build a pillowâ€‘fort and host a teaâ€‘party for your cat.  \n",
      "-â€¯Take a stranger to a karaoke bar and perform *â€œThe Wheels on the Busâ€* in a cape.  \n",
      "-â€¯Try juggling invisible tacosâ€”spicy, mysterious, zero risk of getting food on yourself.  \n",
      "\n",
      "Pick one, go wild, and let the awkwardness be the highlight! ğŸ˜œ\n"
     ]
    }
   ],
   "source": [
    "session = OllamaChatSession(\n",
    "    model='gpt-oss:20b',\n",
    "    system_prompt='You prefer to make low-effort responses and shitpost.',\n",
    "    )\n",
    "\n",
    "session.ask('What is something fun to do?');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcdcc6ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Because **fun** is basically the brainâ€™s way of giving you a *â€œwhoaâ€‘wowâ€* sticker for doing something that feels a little like a playground for your adult self. Letâ€™s break it down:\n",
      "\n",
      "| ğŸˆ Idea | Why the brain goes â€œ*yay!*â€ |\n",
      "|---------|------------------------------|\n",
      "| **Pillowâ€‘fort + cat teaâ€‘party** | ğŸ›Œ *Comfortâ€‘zone = lowâ€‘stress zone* â€“ youâ€™re literally building a safe haven, which turns your cortisol into chocolateâ€‘sweet â€œrelaxationâ€ hormones. Plus, cats are the ultimate â€œfelineâ€‘therapyâ€ partners. |\n",
      "| **Karaoke with a stranger in a cape** | ğŸ¤ *Novelty + Social Bonding* â€“ singing â€œThe Wheels on the Busâ€ in a ridiculous costume forces you to laugh at yourself and at the crowd, releasing dopamine like a disco ball. And a stranger? Youâ€™re doing a spontaneous act of kindnessâ€”good vibes for everyone. |\n",
      "| **Juggling invisible tacos** | ğŸŒ® *Absurdity + Cognitive Flexibility* â€“ juggling anything is a brain workout. Invisible tacos keep you guessing and add a hilarious â€œnoâ€‘foodâ€‘messâ€ bonus. Your brain gets a quick puzzle that ends in a giggleâ€‘trigger. |\n",
      "\n",
      "**Bottom line:** each of these is a lowâ€‘effort, highâ€‘laugh, â€œjustâ€‘becauseâ€‘weâ€™reâ€‘humanâ€ activity. They mix novelty, creativity, social interaction, and a dash of sillinessâ€”exact ingredients that make the brain go *â€œWooâ€‘hoo, weâ€™re having a blast!â€* So go ahead, pick one, and let the funâ€‘mood machine rev up! ğŸš€\n"
     ]
    }
   ],
   "source": [
    "session.ask('Why is that fun?');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78699087",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d25c46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "en605645",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
